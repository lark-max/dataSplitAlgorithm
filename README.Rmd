---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# dataSplitAlgorithm

<!-- badges: start -->
This package can be used to split rainfall-runoff data into three data
subsets(Train, Test, Validation) with similar data distribution characteristics.
<!-- badges: end -->

## Installation

You can install the development version of dataSplitAlgorithm like so:

``` r
devtools::install_github("lark-max/dataSplitAlgorithm")
```
You can then use `library(dataSplitAlgorithm)` to load the package.

## Instruction
The package has several built-in data splitting algorithms, such as SOMPLEX, MDUPLEX, SBSS-P, etc. 
These algorithms are encapsulated and used by the user only by calling the function `dataSplit`.  
Specific call formats such as:  

```r
result = dataSplit(data,list(sel.alg = "SOMPLEX", writeFile = TRUE))
```
  
The parameters of the function are composed of two parts. The first parameter `data` is usually the rainfall runoff data in data.frame or matrix format, and set the first column as the subscript column. For the specific format requirements, please refer to the documentation of the built-in data set(`dataSplitAlgorithm_data_small`).  

  
The second parameter `control` is a list of customized information, such as the selected data splitting algorithm, the proportion of subsets, whether the output file is required and the output file name, etc. These information have default defaults, you can refer to the  `par.default()` provided in the package, which is shown as below:
```r
`include.inp`	
Whether the input vector is included when calculating Euclidean distance between samples, which defaults to TRUE

`seed`	
Seed number, which defaults to 1000

`sel.alg`	
Algorithm selection, includes SOMPLEX, MDUPLEX, DUPLEX, SBSS.P, TC, which defaults to "MDUPLEX"

`prop.Tr`	
The proportion of data allocated to the training set, which defaults to 0.6

`prop.Ts`	
The proportion of data allocated to the test set, which defaults to 0.2

`Train`	
The name of the training set when the output file is required, which defaults to "Train.txt"

`Test`	
The name of the test set when the output file is required, which defaults to "Test.txt"

`Validation`	
The name of the validation set when the output file is required, which defaults to "Valid.txt"

`loc.calib`	
If using the TC algorithm, you can also specify the location of the splitting range, which defaults to c(0,0.6)

`writeFile`	
Whether to output the partition result to a txt file, which defaults to TRUE
```

## Example

The following example can be run directly from the user's Rstudio client. 

```{r example}
library(dataSplitAlgorithm)
## basic example code
data("dataSplitAlgorithm_data_small")
result = dataSplit(dataSplitAlgorithm_data_small, control = list(sel.alg = "MDUPLEX",writeFile = FALSE))

data("dataSplitAlgorithm_data_middle")
result = dataSplit(dataSplitAlgorithm_data_middle, control = list(sel.alg = "SBSS.P",writeFile = FALSE))

data("dataSplitAlgorithm_data_large")
result = dataSplit(dataSplitAlgorithm_data_large, control = list(sel.alg = "SOMPLEX",writeFile = FALSE))
```

## Details

The package also integrates the function of adjunct validation. The metric `AUC` is used to analyze the similarity of data distribution features 
among the sample subsets obtained by various data segmentation algorithms, which can be calculated by invoking the function `getAUC`.  
For example:
``` r
data("dataSplitAlgorithm_data_small")
res_split = dataSplit(dataSplitAlgorithm_data_small,list(sel.alg = "MDUPLEX",writeFile = FALSE))
res_auc = getAUC(res_split$Train,res_split$Validation)
```  
In the above example, the value range of `res_auc` is [0,1], and the closer the value is to 0.5, the more similar the data distribution 
characteristics between the two sample subsets are.

## References

Chen, J., Zheng F., May R., Guo D., Gupta H., and Maier H. R.(2022). Improved data splitting methods for data-driven hydrological model development based on a large number of catchment samples, Journal of Hydrology, 613.

Zheng, F., Chen J., Maier H. R., and Gupta H.(2022). Achieving Robust and Transferable Performance for Conservation‚ÄêBased Models of Dynamical Physical Systems, Water Resources Research, 58(5).

Zheng, F., Chen, J., Ma, Y.,  Chen Q., Maier H. R., and Gupta H.(2023). A Robust Strategy to Account for Data Sampling Variability in the Development of Hydrological Models, Water Resources Research, 59(3).
